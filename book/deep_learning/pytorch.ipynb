{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is an open source optimized tensor library for deep learning using GPUs and CPUs. It is a deep learning framework that provides a whole stack to preprocess data, model data and deploy the models in cloud. PyTorch leverages <b>CUDA</b> (Compute Unified Device Architecture) which is an API (Application Programming Interface) developed by Nvidia for general computing on GPUs (Graphical Processing Units). This enables us to accelerate the modelling process due to faster computations because CUDA enables us to run the computations on GPU (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are simply arrays that are used to represent data similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
    "\n",
    "A scalar is a single number, and in tensor terms it is a zero dimension tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(1)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting a tensor to a python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector is a single dimension tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix is a 2 dimensional tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "M = torch.tensor([[7, 8],\n",
    "                [9, 10]])\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7033, 0.0072, 0.0208, 0.3163],\n",
       "        [0.7173, 0.9197, 0.2152, 0.3863],\n",
       "        [0.9060, 0.1341, 0.1837, 0.0620]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random tensor with similar shape to an image tensor. $1^{st}$ dimension is the color channels, $2^{nd}$ dimension is the height and $3^{rd}$ dimension is the width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.6252e-01, 6.8493e-01, 9.2644e-01,  ..., 8.3281e-01,\n",
       "          7.5196e-01, 7.8708e-01],\n",
       "         [7.8042e-01, 3.9105e-01, 5.7301e-01,  ..., 4.3212e-01,\n",
       "          8.2964e-01, 4.6402e-02],\n",
       "         [5.8364e-01, 7.7383e-01, 3.3439e-02,  ..., 9.6866e-01,\n",
       "          1.3825e-02, 2.1600e-02],\n",
       "         ...,\n",
       "         [3.3342e-01, 7.2911e-01, 8.7512e-01,  ..., 7.0167e-01,\n",
       "          5.9874e-02, 9.1148e-01],\n",
       "         [6.6047e-01, 4.3686e-02, 1.5338e-01,  ..., 1.2216e-01,\n",
       "          8.4989e-01, 6.1421e-02],\n",
       "         [3.1999e-01, 7.4338e-01, 9.2654e-01,  ..., 5.8881e-01,\n",
       "          3.0616e-01, 7.7568e-01]],\n",
       "\n",
       "        [[7.2034e-01, 6.9610e-01, 5.9102e-01,  ..., 9.2958e-01,\n",
       "          1.6569e-01, 1.7074e-01],\n",
       "         [9.6824e-01, 4.8632e-02, 4.4943e-02,  ..., 6.4951e-01,\n",
       "          6.9099e-02, 1.9791e-01],\n",
       "         [9.3951e-01, 8.1072e-02, 7.9214e-01,  ..., 3.6702e-01,\n",
       "          2.4208e-01, 6.9468e-01],\n",
       "         ...,\n",
       "         [1.8619e-01, 3.4491e-01, 9.5325e-01,  ..., 4.5718e-01,\n",
       "          5.4849e-01, 6.4172e-01],\n",
       "         [5.5771e-01, 3.1709e-01, 2.2389e-01,  ..., 6.9642e-01,\n",
       "          7.1515e-01, 7.4441e-02],\n",
       "         [5.0858e-01, 7.5540e-01, 3.3978e-01,  ..., 1.5260e-01,\n",
       "          8.6931e-01, 3.8591e-01]],\n",
       "\n",
       "        [[8.7751e-01, 6.9955e-01, 7.0166e-01,  ..., 3.3498e-01,\n",
       "          5.7078e-01, 4.0291e-01],\n",
       "         [2.5125e-01, 6.8815e-01, 8.9422e-01,  ..., 8.2766e-01,\n",
       "          1.3912e-01, 5.0958e-01],\n",
       "         [3.0558e-01, 3.4201e-01, 2.2198e-01,  ..., 8.4678e-01,\n",
       "          3.1558e-01, 4.6858e-01],\n",
       "         ...,\n",
       "         [5.3595e-01, 7.8463e-01, 9.8089e-01,  ..., 2.0604e-01,\n",
       "          6.1539e-01, 5.5511e-01],\n",
       "         [7.2195e-01, 7.2943e-01, 6.1011e-04,  ..., 6.4422e-01,\n",
       "          7.3042e-01, 1.6702e-01],\n",
       "         [6.3310e-01, 4.8412e-01, 7.5089e-01,  ..., 4.2957e-01,\n",
       "          2.4958e-02, 7.0954e-01]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_image_tensor = torch.rand(size = (3,224,224))\n",
    "rand_image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tensor = torch.zeros(size = (3,4))\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_tensor = torch.ones(size = (3,4))\n",
    "one_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default datatype in pytorch is float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_tensor = torch.arange(0,10)\n",
    "range_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors-like\n",
    "torch.zeros_like(range_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three most important parmeters when creating tensors are <b>dtype, device</b> and <b>requires_grad</b>.\n",
    "\n",
    "1. Some datatypes are specific for GPUs and some are specific for CPUs. Generally if you see torch.cuda anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
    "The different types of bits for datatype has to do with the precision of the value. The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
    "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
    "\n",
    "2. The argument device refers to what device the tensor is saved on. If one of your tensors is on the CPU and the other is on the GPU, you get an error when you perform a computation on them.\n",
    "\n",
    "3. requires_grad refers to whether or not to track gradients with the tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of the tensor is  torch.float32\n",
      "Device the tensor is save on is  cpu\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.tensor([1.0,2.0,3.0],\n",
    "             dtype = torch.float32,\n",
    "             device = 'cpu',\n",
    "             requires_grad=False,)\n",
    "print('Datatype of the tensor is ',x_tensor.dtype)\n",
    "print('Device the tensor is save on is ',x_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting dtype of a tensor\n",
    "x16_tensor = x_tensor.type(torch.float16)\n",
    "x16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.], dtype=torch.float16)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element wise multiplication\n",
    "torch.mul(x16_tensor,10)\n",
    "x16_tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  0.,  1.], dtype=torch.float16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.subtract(x16_tensor,2)\n",
    "x16_tensor - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 6.], dtype=torch.float16)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x16_tensor,3)\n",
    "x16_tensor + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 1.0000, 1.5000], dtype=torch.float16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.divide(x16_tensor,2)\n",
    "x16_tensor/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1568, 0.9598, 1.6082],\n",
       "        [1.3775, 1.4593, 1.5127],\n",
       "        [1.1015, 1.6211, 1.3316]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tensor = torch.rand(size = (3,3))\n",
    "# you can use @ to perform matrix multiplication\n",
    "rand_tensor @ rand_tensor\n",
    "# you can use the predefined method\n",
    "torch.matmul(rand_tensor,rand_tensor)\n",
    "# mm is short form of matmul\n",
    "torch.mm(rand_tensor,rand_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several other functions and methods which are more or less similar to the ones on numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place operations Operations that store the result into the operand are called in-place. They are denoted by a _ suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0531, 5.3376, 5.2132],\n",
       "        [5.3989, 5.6977, 5.5037],\n",
       "        [5.8739, 5.3917, 5.2995]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tensor.add_(5)\n",
    "rand_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch and NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform numpy array to pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(1.0,10.0)\n",
    "arr_tensor = torch.from_numpy(arr)\n",
    "arr, arr_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.dtype, arr_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_numpy = arr_tensor.numpy()\n",
    "tensor_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_numpy.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a random seed. When using a jupyter notebook, you shall set random seed everytime you use random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11d508b10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "# configuration of the GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for GPU access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if False it means GPU is not available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its not likely that you always have access to a GPU. So we can set a device agnostic code as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am using a mac, I can check what type of accelerator I have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.accelerator.is_available():\n",
    "    device = torch.accelerator.current_accelerator()\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPS in the context of PyTorch refers to the Metal Performance Shaders backend.\n",
    "\n",
    "* **Metal:** This is Apple's proprietary API (Application Programming Interface) for programming their GPUs (Graphics Processing Units). It provides low-level access to the graphics hardware for maximum performance in graphics rendering and parallel computations.\n",
    "* **Metal Performance Shaders (MPS):** This is a framework built on top of Metal. It's a collection of highly optimized compute and graphics shaders specifically designed to integrate into applications using the Metal API. These shaders are fine-tuned for the unique characteristics of Apple's GPUs (found in Apple Silicon and some older AMD-based Macs).\n",
    "* **MPS Backend in PyTorch:** PyTorch has integrated MPS as a backend, allowing you to run tensor computations and train neural networks on Apple GPUs. By moving your PyTorch tensors and models to an \"mps\" device (e.g., `torch.device(\"mps\")`), you can leverage the power of the Apple GPU for significantly faster computations compared to running on the CPU.\n",
    "\n",
    "**Key benefits of using the MPS backend in PyTorch:**\n",
    "\n",
    "* **Accelerated Training and Inference:** Utilizing the GPU's parallel processing capabilities can drastically reduce the time required for training complex models and performing inference.\n",
    "* **Optimized Performance:** MPS is specifically designed for Apple's hardware, meaning the operations are highly optimized for their architecture.\n",
    "* **Ease of Use:** PyTorch's integration allows you to switch to GPU computation with minimal code changes, similar to using CUDA on NVIDIA GPUs.\n",
    "\n",
    "**In summary, MPS in PyTorch enables high-performance training and inference on Apple Silicon and compatible AMD GPUs by utilizing Apple's Metal Performance Shaders framework.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Tensors and Models on the GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_tensor = torch.tensor([1,2,3], device=device)\n",
    "cpu_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 'to' to change the device. incase of GPU availability it shows cuda with the index of the GPU used\n",
    "cpu_tensor.to(device)\n",
    "cpu_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert a tensor on GPU to numpy is not possible. The device has to be changed to CPU and then converted to numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing and converting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>nn</b> module of torch provides all the building blocks for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subclass the nn.module class that contains all the building blocks required\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.weights = nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
    "\n",
    "    def forward(self,x: torch.Tensor):\n",
    "        return x*self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "la = LinearRegression()\n",
    "list(la.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of named parameters\n",
    "la.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
